@InProceedings{Long_2015_CVPR,
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
title = {Fully Convolutional Networks for Semantic Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{mittelman2015time,
  title={Time-series modeling with undecimated fully convolutional neural networks},
  author={Mittelman, Roni},
  journal={arXiv preprint arXiv:1508.00317},
  year={2015}
}

@article{wang2016time,
  title={Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline},
  author={Wang, Zhiguang and Yan, Weizhong and Oates, Tim},
  journal={arXiv preprint arXiv:1611.06455},
  year={2016}
}


@article{langkvist2014review,
  title={A review of unsupervised feature learning and deep learning for time-series modeling},
  author={L{\"a}ngkvist, Martin and Karlsson, Lars and Loutfi, Amy},
  journal={Pattern Recognition Letters},
  volume={42},
  pages={11--24},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{geurts2001pattern,
  title={Pattern extraction for time series classification},
  author={Geurts, Pierre},
  booktitle={European Conference on Principles of Data Mining and Knowledge Discovery},
  pages={115--127},
  year={2001},
  organization={Springer}
}


@inproceedings{waser2013removing,
  title={Removing cardiac interference from the electroencephalogram using a modified Pan-Tompkins algorithm and linear regression},
  author={Waser, Markus and Garn, Heinrich},
  booktitle={Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE},
  pages={2028--2031},
  year={2013},
  organization={IEEE}
}

@article{garcia2016application,
  title={Application of the relative wavelet energy to heart rate independent detection of atrial fibrillation},
  author={García, Manuel and Ródenas, Juan and Alcaraz, Raúl and Rieta, José J},
  journal={Computer methods and programs in biomedicine},
  volume={131},
  pages={157--168},
  year={2016},
  publisher={Elsevier}
}


@article{rodenas2015wavelet,
  title={Wavelet Entropy Automatically Detects Episodes of Atrial Fibrillation from Single-Lead Electrocardiograms},
  author={R{\'o}denas, Juan and Garc{\'\i}a, Manuel and Alcaraz, Ra{\'u}l and Rieta, Jos{\'e} J},
  journal={Entropy},
  volume={17},
  number={9},
  pages={6179--6199},
  year={2015},
  publisher={Multidisciplinary Digital Publishing Institute}
}


@inproceedings{alcaraz2006wavelet,
  title={Wavelet sample entropy: A new approach to predict termination of atrial fibrillation},
  author={Alcaraz, R and Vay{\'a}, C and Cervig{\'o}n, R and S{\'a}nchez, C and Rieta, JJ},
  booktitle={Computers in Cardiology, 2006},
  pages={597--600},
  year={2006},
  organization={IEEE}
}


@article{purerfellner2014p,
  title={P-wave evidence as a method for improving algorithm to detect atrial fibrillation in insertable cardiac monitors},
  author={P{\"u}rerfellner, Helmut and Pokushalov, Evgeny and Sarkar, Shantanu and Koehler, Jodi and Zhou, Ren and Urban, Lubos and Hindricks, Gerhard},
  journal={Heart Rhythm},
  volume={11},
  number={9},
  pages={1575--1583},
  year={2014},
  publisher={Elsevier}
}


@article{du2014novel,
  title={A Novel Method for Real-Time Atrial Fibrillation Detection in Electrocardiograms Using Multiple Parameters},
  author={Du, Xiaochuan and Rao, Nini and Qian, Mengyao and Liu, Dingyu and Li, Jie and Feng, Wei and Yin, Lixue and Chen, Xu},
  journal={Annals of Noninvasive Electrocardiology},
  volume={19},
  number={3},
  pages={217--225},
  year={2014},
  publisher={Wiley Online Library}
}

@article{ladavich2015rate,
  title={Rate-independent detection of atrial fibrillation by statistical modeling of atrial activity},
  author={Ladavich, Steven and Ghoraani, Behnaz},
  journal={Biomedical Signal Processing and Control},
  volume={18},
  pages={274--281},
  year={2015},
  publisher={Elsevier}
}

@article{petrenas2012echo,
  title={An echo state neural network for QRST cancellation during atrial fibrillation},
  author={Petrenas, Andrius and Marozas, Vaidotas and Sornmo, Leif and Lukosevicius, Arunas},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={59},
  number={10},
  pages={2950--2957},
  year={2012},
  publisher={IEEE}
}

@article{reiffel2010practice,
  title={Practice patterns among United States cardiologists for managing adults with atrial fibrillation (from the AFFECTS Registry)},
  author={Reiffel, James A and Kowey, Peter R and Myerburg, Robert and Naccarelli, Gerald V and Packer, Douglas L and Pratt, Craig M and Reiter, Michael J and Waldo, Albert L and Committee, AFFECTS Scientific Advisory and others},
  journal={The American journal of cardiology},
  volume={105},
  number={8},
  pages={1122--1129},
  year={2010},
  publisher={Elsevier}
}


@inproceedings{torch,
  title={Torch7: A matlab-like environment for machine learning},
  author={Collobert, Ronan and Kavukcuoglu, Koray and Farabet, Cl{\'e}ment},
  booktitle={BigLearn, NIPS Workshop},
  number={EPFL-CONF-192376},
  year={2011}
}

@inproceedings{caffe,
  title={Caffe: Convolutional architecture for fast feature embedding},
  author={Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  pages={675--678},
  year={2014},
  organization={ACM}
}


@article{haykin2004comprehensive,
  title={A comprehensive foundation},
  author={Haykin, Simon and Network, Neural},
  journal={Neural Networks},
  volume={2},
  number={2004},
  year={2004}
}

@article{riesenhuber1999hierarchical,
  title={Hierarchical models of object recognition in cortex},
  author={Riesenhuber, Maximilian and Poggio, Tomaso},
  journal={Nature neuroscience},
  volume={2},
  number={11},
  pages={1019--1025},
  year={1999},
  publisher={Nature Publishing Group}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European Conference on Computer Vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{yosinski2015understanding,
  title={Understanding neural networks through deep visualization},
  author={Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  journal={arXiv preprint arXiv:1506.06579},
  year={2015}
}


@book{werbos1994roots,
  title={The roots of backpropagation: from ordered derivatives to neural networks and political forecasting},
  author={Werbos, Paul John},
  volume={1},
  year={1994},
  publisher={John Wiley \& Sons}
}


@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}


@techreport{TF,
title = {TensorFlow: A system for large-scale machine learning},
author  = {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year  = 2016,
URL = {https://arxiv.org/abs/1605.08695},
note  = {arXiv preprint},
institution = {Google Brain}
}

@unpublished{Goodfellow-et-al-2016-Book,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    note={Book in preparation for MIT Press},
    url={http://www.deeplearningbook.org},
    year={2016}
}

@unpublished{nnsdl,
  author = {Michael Nielsen},
  title = {{Neural Networks and Deep Learning}},
  year = 2016,
  url = {http://neuralnetworksanddeeplearning.com/},
  note = {Accessed: \today}
}

@unpublished{gibiansky,
  author = {Andrew Gibiansky},
  title = {{Math to Code}},
  year = 2016,
  url = {http://andrew.gibiansky.com/},
  note = {Accessed: \today}
}

@unpublished{deeplearningdotnet,
  title = {{Deep Learning} moving beyond shallow machine learning since 2006},
  year = 2016,
  url = {http://deeplearning.net/tutorial/},
  note = {Accessed: \today}
}

@unpublished{stanfordlectures,
  author = {Andrej Karpathy and Fei-Fei Li and Justin Johnson},
  title = {{CS231n} Convolutional Neural Networks for Visual Recognition. },
  year = 2016,
  url = {http://cs231n.github.io/},
  note = {Accessed: \today}
}

@unpublished{oxfordlectures,
  author = {Nando de Freitas},
  title = {{Machine Learning}},
  year = 2015,
  url = {https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/},
  note = {Accessed: \today}
}

@unpublished{karpathyblog,
  author = {Andrej Karpathy},
  title = {{Andrej Karpathy blog} Hacker's guide to Neural Networks},
  url = {http://karpathy.github.io/neuralnets/},
  note = {Accessed: \today}
}

@unpublished{convnetjs,
  author = {Andrej Karpathy},
  title = {{ConvNetJS} Deep Learning in your browser},
  url = {http://cs.stanford.edu/people/karpathy/convnetjs/},
  note = {Accessed: \today}
}
@unpublished{gibianskysource,
  author = {Andrew Gibiansky},
  title = {Neural networking code snippets and sources},
  year = 2012,
  url = {https://github.com/gibiansky/experiments/tree/master/neural-network},
  note = {Accessed: \today}
}
@unpublished{DV,
  author = {Csaba Botos},
  title = {Deep Vision Library},
  year = 2016,
  url = {https://github.com/botcs/deepvision},
  note = {Accessed: \today}
}
@unpublished{vlog1,
  author = {Hugo Larochelle},
  title = {neural network tutorial},
  url = {https://youtu.be/SGZ6BttHMPw},
  note = {Accessed: \today}
}

@unpublished{softmax,
  author = {Moos Hueting},
  url = {http://math.stackexchange.com/questions/945871},
  note = {Accessed: \today}
}
@misc{mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann and Cortes, Corinna and Burges, Christopher JC},
  year={1998}
}


@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Oct},
  pages={2825--2830},
  year={2011}
}
@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers Inc.}
}

@PhdThesis{akthesis,
author = {Andrej Karpathy},
title = {Connecting Images and Natural Language},
school = {Stanford University},
year = {2016}
}

@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

@misc{shewchuk1994introduction,
  title={An introduction to the conjugate gradient method without the agonizing pain},
  author={Shewchuk, Jonathan Richard},
  year={1994},
  publisher={Carnegie-Mellon University. Department of Computer Science}
}

@article{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning.},
  author={Sutskever, Ilya and Martens, James and Dahl, George E and Hinton, Geoffrey E},
  journal={ICML (3)},
  volume={28},
  pages={1139--1147},
  year={2013}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{rmsprop,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural Networks for Machine Learning},
  volume={4},
  number={2},
  year={2012}
}

@book{qlearn-case,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  year={1994},
  publisher={University of Cambridge, Department of Engineering}
}

@book{onlinelearn,
  title={On-line learning in neural networks},
  author={Saad, David},
  volume={17},
  year={2009},
  publisher={Cambridge University Press}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@article{specht1991general,
  title={A general regression neural network},
  author={Specht, Donald F},
  journal={IEEE transactions on neural networks},
  volume={2},
  number={6},
  pages={568--576},
  year={1991},
  publisher={IEEE}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1--9},
  year={2015}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{welch1967use,
  title={The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms},
  author={Welch, Peter D},
  journal={IEEE Transactions on audio and electroacoustics},
  volume={15},
  number={2},
  pages={70--73},
  year={1967}
}

@misc{pham2006pyaudio,
  title={Pyaudio: Portaudio v19 python bindings},
  author={Pham, Hubert},
  year={2006},
  publisher={PyAudio}
}


@unpublished{bestmnist,
  author = {Rodrigo Benenson},
  title = {{Classification datasets results}},
  year = 2016,
  url = {http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html},
  note = {Accessed: \today}
}

@article{cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  publisher={Citeseer}
}

@article{hinton2012improving,
  title={Improving neural networks by preventing co-adaptation of feature detectors},
  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:1207.0580},
  year={2012}
}

@inproceedings{dropcon,
  title={Regularization of neural networks using dropconnect},
  author={Wan, Li and Zeiler, Matthew and Zhang, Sixin and Cun, Yann L and Fergus, Rob},
  booktitle={Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
  pages={1058--1066},
  year={2013}
}
@article{wta,
  title={Two k-winners-take-all networks with discontinuous activation functions},
  author={Liu, Qingshan and Wang, Jun},
  journal={Neural Networks},
  volume={21},
  number={2},
  pages={406--413},
  year={2008},
  publisher={Elsevier}
}

@article{milo2002network,
  title={Network motifs: simple building blocks of complex networks},
  author={Milo, Ron and Shen-Orr, Shai and Itzkovitz, Shalev and Kashtan, Nadav and Chklovskii, Dmitri and Alon, Uri},
  journal={Science},
  volume={298},
  number={5594},
  pages={824--827},
  year={2002},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={427--436},
  year={2015},
  organization={IEEE}
}


@unpublished{breakingclass,
  author = {Andrej Karpathy},
  title = {{Breaking Linear Classifiers on ImageNet}},
  year = 2015,
  url = {http://karpathy.github.io/2015/03/30/breaking-convnets/},
  note = {Accessed: \today}
}

@article{yosinski2015understanding,
  title={Understanding neural networks through deep visualization},
  author={Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  journal={arXiv preprint arXiv:1506.06579},
  year={2015}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={248--255},
  year={2009},
  organization={IEEE}
}
@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@inproceedings{malhotra2015long,
  title={Long short term memory networks for anomaly detection in time series},
  author={Malhotra, Pankaj and Vig, Lovekesh and Shroff, Gautam and Agarwal, Puneet},
  booktitle={Proceedings},
  pages={89},
  year={2015},
  organization={Presses universitaires de Louvain}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}
@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}


@article{martis_ecg_2013,
	title = {{ECG} beat classification using {PCA}, {LDA}, {ICA} and {Discrete} {Wavelet} {Transform}},
	volume = {8},
	issn = {1746-8094},
	url = {http://www.sciencedirect.com/science/article/pii/S1746809413000062},
	doi = {10.1016/j.bspc.2013.01.005},
	abstract = {Electrocardiogram (ECG) is the P-QRS-T wave, representing the cardiac function. The information concealed in the ECG signal is useful in detecting the disease afflicting the heart. It is very difficult to identify the subtle changes in the ECG in time and frequency domains. The Discrete Wavelet Transform (DWT) can provide good time and frequency resolutions and is able to decipher the hidden complexities in the ECG. In this study, five types of beat classes of arrhythmia as recommended by Association for Advancement of Medical Instrumentation (AAMI) were analyzed namely: non-ectopic beats, supra-ventricular ectopic beats, ventricular ectopic beats, fusion betas and unclassifiable and paced beats. Three dimensionality reduction algorithms; Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Independent Component Analysis (ICA) were independently applied on DWT sub bands for dimensionality reduction. These dimensionality reduced features were fed to the Support Vector Machine (SVM), neural network (NN) and probabilistic neural network (PNN) classifiers for automated diagnosis. ICA features in combination with PNN with spread value (σ) of 0.03 performed better than the PCA and LDA. It has yielded an average sensitivity, specificity, positive predictive value (PPV) and accuracy of 99.97\%, 99.83\%, 99.21\% and 99.28\% respectively using ten-fold cross validation scheme.},
	number = {5},
	urldate = {2017-05-03},
	journal = {Biomedical Signal Processing and Control},
	author = {Martis, Roshan Joy and Acharya, U. Rajendra and Min, Lim Choo},
	month = sep,
	year = {2013},
	keywords = {Association for Advancement of Medical Instrumentation (AAMI), Discrete Wavelet Transform (DWT), Electrocardiogram (ECG), Independent Component Analysis (ICA), Linear Discriminant Analysis (LDA), Principal Component Analysis (PCA), Support Vector Machine (SVM)},
	pages = {437--448},
	file = {ScienceDirect Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/R9ZGB5J5/S1746809413000062.html:text/html}
}

@inproceedings{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2017-05-07},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {Full Text PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/6TCTGJUX/Long et al. - 2015 - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf;Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/T3ZI9HJE/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html:text/html}
}

@article{miyamoto_gated_2016,
	title = {Gated {Word}-{Character} {Recurrent} {Language} {Model}},
	url = {http://arxiv.org/abs/1606.01700},
	abstract = {We introduce a recurrent neural network language model (RNN-LM) with long short-term memory (LSTM) units that utilizes both character-level and word-level inputs. Our model has a gate that adaptively finds the optimal mixture of the character-level and word-level inputs. The gate creates the final vector representation of a word by combining two distinct representations of the word. The character-level inputs are converted into vector representations of words using a bidirectional LSTM. The word-level inputs are projected into another high-dimensional space by a word lookup table. The final vector representations of words are used in the LSTM language model which predicts the next word given all the preceding words. Our model with the gating mechanism effectively utilizes the character-level inputs for rare and out-of-vocabulary words and outperforms word-level language models on several English corpora.},
	urldate = {2017-05-07},
	journal = {arXiv:1606.01700 [cs]},
	author = {Miyamoto, Yasumasa and Cho, Kyunghyun},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.01700},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1606.01700 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/IXI4MENC/Miyamoto and Cho - 2016 - Gated Word-Character Recurrent Language Model.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/M26XP9P2/1606.html:text/html}
}

@misc{noauthor_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2017-05-07},
	file = {Understanding LSTM Networks -- colah's blog:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/EXMP7N9Q/2015-08-Understanding-LSTMs.html:text/html}
}

@inproceedings{long_fully_2015-1,
	title = {Fully convolutional networks for semantic segmentation},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2017-05-07},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {long_shelhamer_fcn.pdf:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/ACGI48EQ/long_shelhamer_fcn.pdf:application/pdf}
}

@article{vinyals_matching_2016,
	title = {Matching {Networks} for {One} {Shot} {Learning}},
	url = {file:///home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/47TNEP77/1606.html},
	urldate = {2017-05-07},
	author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
	month = jun,
	year = {2016},
	file = {Full Text PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/N3RP7X5Z/Vinyals et al. - 2016 - Matching Networks for One Shot Learning.pdf:application/pdf;Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/K7A4U2IM/1606.html:text/html}
}

@article{santoro_one-shot_2016,
	title = {One-shot {Learning} with {Memory}-{Augmented} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.06065},
	abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.},
	urldate = {2017-05-07},
	journal = {arXiv:1605.06065 [cs]},
	author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
	month = may,
	year = {2016},
	note = {arXiv: 1605.06065},
	keywords = {Computer Science - Learning},
	annote = {Comment: 13 pages, 8 figures},
	file = {arXiv\:1605.06065 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/J26EGKB8/Santoro et al. - 2016 - One-shot Learning with Memory-Augmented Neural Net.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/X64AS7U8/1605.html:text/html}
}
