
@article{martis_ecg_2013,
	title = {{ECG} beat classification using {PCA}, {LDA}, {ICA} and {Discrete} {Wavelet} {Transform}},
	volume = {8},
	issn = {1746-8094},
	url = {http://www.sciencedirect.com/science/article/pii/S1746809413000062},
	doi = {10.1016/j.bspc.2013.01.005},
	abstract = {Electrocardiogram (ECG) is the P-QRS-T wave, representing the cardiac function. The information concealed in the ECG signal is useful in detecting the disease afflicting the heart. It is very difficult to identify the subtle changes in the ECG in time and frequency domains. The Discrete Wavelet Transform (DWT) can provide good time and frequency resolutions and is able to decipher the hidden complexities in the ECG. In this study, five types of beat classes of arrhythmia as recommended by Association for Advancement of Medical Instrumentation (AAMI) were analyzed namely: non-ectopic beats, supra-ventricular ectopic beats, ventricular ectopic beats, fusion betas and unclassifiable and paced beats. Three dimensionality reduction algorithms; Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Independent Component Analysis (ICA) were independently applied on DWT sub bands for dimensionality reduction. These dimensionality reduced features were fed to the Support Vector Machine (SVM), neural network (NN) and probabilistic neural network (PNN) classifiers for automated diagnosis. ICA features in combination with PNN with spread value (Ïƒ) of 0.03 performed better than the PCA and LDA. It has yielded an average sensitivity, specificity, positive predictive value (PPV) and accuracy of 99.97\%, 99.83\%, 99.21\% and 99.28\% respectively using ten-fold cross validation scheme.},
	number = {5},
	urldate = {2017-05-03},
	journal = {Biomedical Signal Processing and Control},
	author = {Martis, Roshan Joy and Acharya, U. Rajendra and Min, Lim Choo},
	month = sep,
	year = {2013},
	keywords = {Association for Advancement of Medical Instrumentation (AAMI), Discrete Wavelet Transform (DWT), Electrocardiogram (ECG), Independent Component Analysis (ICA), Linear Discriminant Analysis (LDA), Principal Component Analysis (PCA), Support Vector Machine (SVM)},
	pages = {437--448},
	file = {ScienceDirect Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/R9ZGB5J5/S1746809413000062.html:text/html}
}

@inproceedings{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2017-05-07},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {Full Text PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/6TCTGJUX/Long et al. - 2015 - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf;Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/T3ZI9HJE/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html:text/html}
}

@article{miyamoto_gated_2016,
	title = {Gated {Word}-{Character} {Recurrent} {Language} {Model}},
	url = {http://arxiv.org/abs/1606.01700},
	abstract = {We introduce a recurrent neural network language model (RNN-LM) with long short-term memory (LSTM) units that utilizes both character-level and word-level inputs. Our model has a gate that adaptively finds the optimal mixture of the character-level and word-level inputs. The gate creates the final vector representation of a word by combining two distinct representations of the word. The character-level inputs are converted into vector representations of words using a bidirectional LSTM. The word-level inputs are projected into another high-dimensional space by a word lookup table. The final vector representations of words are used in the LSTM language model which predicts the next word given all the preceding words. Our model with the gating mechanism effectively utilizes the character-level inputs for rare and out-of-vocabulary words and outperforms word-level language models on several English corpora.},
	urldate = {2017-05-07},
	journal = {arXiv:1606.01700 [cs]},
	author = {Miyamoto, Yasumasa and Cho, Kyunghyun},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.01700},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1606.01700 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/IXI4MENC/Miyamoto and Cho - 2016 - Gated Word-Character Recurrent Language Model.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/M26XP9P2/1606.html:text/html}
}

@misc{chris_olah_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2017-05-07},
	journal = {Understanding LSTM networks},
	author = {Chris Olah},
	file = {Understanding LSTM Networks -- colah's blog:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/EXMP7N9Q/2015-08-Understanding-LSTMs.html:text/html}
}

@inproceedings{long_fully_2015-1,
	title = {Fully convolutional networks for semantic segmentation},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2017-05-07},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {long_shelhamer_fcn.pdf:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/ACGI48EQ/long_shelhamer_fcn.pdf:application/pdf}
}

@article{vinyals_matching_2016,
	title = {Matching {Networks} for {One} {Shot} {Learning}},
	url = {file:///home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/47TNEP77/1606.html},
	urldate = {2017-05-07},
	author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
	month = jun,
	year = {2016},
	file = {Full Text PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/N3RP7X5Z/Vinyals et al. - 2016 - Matching Networks for One Shot Learning.pdf:application/pdf;Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/K7A4U2IM/1606.html:text/html}
}

@article{santoro_one-shot_2016,
	title = {One-shot {Learning} with {Memory}-{Augmented} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.06065},
	abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.},
	urldate = {2017-05-07},
	journal = {arXiv:1605.06065 [cs]},
	author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
	month = may,
	year = {2016},
	note = {arXiv: 1605.06065},
	keywords = {Computer Science - Learning},
	annote = {Comment: 13 pages, 8 figures},
	file = {arXiv\:1605.06065 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/J26EGKB8/Santoro et al. - 2016 - One-shot Learning with Memory-Augmented Neural Net.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/X64AS7U8/1605.html:text/html}
}

@article{quang_dann:_2015,
	title = {{DANN}: a deep learning approach for annotating the pathogenicity of genetic variants},
	volume = {31},
	issn = {1367-4811},
	shorttitle = {{DANN}},
	doi = {10.1093/bioinformatics/btu703},
	abstract = {Annotating genetic variants, especially non-coding variants, for the purpose of identifying pathogenic variants remains a challenge. Combined annotation-dependent depletion (CADD) is an algorithm designed to annotate both coding and non-coding variants, and has been shown to outperform other annotation algorithms. CADD trains a linear kernel support vector machine (SVM) to differentiate evolutionarily derived, likely benign, alleles from simulated, likely deleterious, variants. However, SVMs cannot capture non-linear relationships among the features, which can limit performance. To address this issue, we have developed DANN. DANN uses the same feature set and training data as CADD to train a deep neural network (DNN). DNNs can capture non-linear relationships among features and are better suited than SVMs for problems with a large number of samples and features. We exploit Compute Unified Device Architecture-compatible graphics processing units and deep learning techniques such as dropout and momentum training to accelerate the DNN training. DANN achieves about a 19\% relative reduction in the error rate and about a 14\% relative increase in the area under the curve (AUC) metric over CADD's SVM methodology.
AVAILABILITY AND IMPLEMENTATION: All data and source code are available at https://cbcl.ics.uci.edu/public\_data/DANN/.},
	language = {eng},
	number = {5},
	journal = {Bioinformatics (Oxford, England)},
	author = {Quang, Daniel and Chen, Yifei and Xie, Xiaohui},
	month = mar,
	year = {2015},
	pmid = {25338716},
	pmcid = {PMC4341060},
	keywords = {Algorithms, Area Under Curve, Computer Graphics, Genetic Variation, Genome, Human, Humans, Molecular Sequence Annotation, Neural Networks (Computer), Selection, Genetic, Support Vector Machine},
	pages = {761--763}
}

@article{ganin_domain-adversarial_2015,
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.07818},
	abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.},
	urldate = {2017-05-07},
	journal = {arXiv:1505.07818 [cs, stat]},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, FranÃ§ois and Marchand, Mario and Lempitsky, Victor},
	month = may,
	year = {2015},
	note = {arXiv: 1505.07818},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: Published in JMLR: http://jmlr.org/papers/v17/15-239.html},
	file = {arXiv\:1505.07818 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/KWPDSRXJ/Ganin et al. - 2015 - Domain-Adversarial Training of Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/DN56Z96P/1505.html:text/html}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} method for stochastic optimization},
	shorttitle = {Adam},
	url = {https://arxiv.org/abs/1412.6980},
	urldate = {2017-05-08},
	journal = {arXiv preprint arXiv:1412.6980},
	author = {Kingma, Diederik and Ba, Jimmy},
	year = {2014},
	file = {1412.pdf:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/S7KMIBPE/1412.pdf:application/pdf}
}

@inproceedings{wan_regularization_2013,
	title = {Regularization of neural networks using dropconnect},
	url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2013_wan13},
	urldate = {2017-05-08},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning} ({ICML}-13)},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and Cun, Yann L. and Fergus, Rob},
	year = {2013},
	pages = {1058--1066},
	file = {Regularization of Neural Networks using DropConnect - icml2013.pdf:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/6HUDQERI/icml2013.pdf:application/pdf}
}

@misc{noauthor_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2017-05-08},
	file = {Understanding LSTM Networks -- colah's blog:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/AA4P3Z2J/2015-08-Understanding-LSTMs.html:text/html}
}

@misc{noauthor_tensorflow:_nodate,
	title = {{TensorFlow}: {How} to optimise your input pipeline with queues and multi-threading},
	url = {https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0},
	urldate = {2017-05-08},
	file = {TensorFlow\: How to optimise your input pipeline with queues and multi-threading:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/6ZXR6STP/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0.html:text/html}
}

@misc{noauthor_performance_nodate,
	title = {Performance {Guide}},
	url = {https://www.tensorflow.org/performance/performance_guide},
	urldate = {2017-05-08},
	journal = {TensorFlow},
	file = {Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/ZG79H86D/performance_guide.html:text/html}
}

@misc{noauthor_tensorflow_nodate,
	title = {{TensorFlow}â„¢ {Patterns}},
	url = {http://www.tensorflowpatterns.org/},
	urldate = {2017-05-08},
	file = {TensorFlowâ„¢ Patterns:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/RPBU8QD8/www.tensorflowpatterns.org.html:text/html}
}

@misc{noauthor_cs231n_nodate,
	title = {{CS}231n {Convolutional} {Neural} {Networks} for {Visual} {Recognition}},
	url = {http://cs231n.github.io/},
	urldate = {2017-05-08},
	file = {CS231n Convolutional Neural Networks for Visual Recognition:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/KGR2G5QU/cs231n.github.io.html:text/html}
}

@misc{noauthor_wildml_nodate,
	title = {{WildML} â€“ {AI}, {Deep} {Learning}, {NLP}},
	url = {http://www.wildml.com/},
	urldate = {2017-05-08},
	file = {WildML â€“ AI, Deep Learning, NLP:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/INT92S5T/www.wildml.com.html:text/html}
}

@misc{noauthor_tutorials_nodate,
	title = {Tutorials},
	url = {https://www.tensorflow.org/tutorials/},
	urldate = {2017-05-08},
	journal = {TensorFlow},
	file = {Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/M3JUKZJ4/tutorials.html:text/html}
}

@misc{noauthor_learning_nodate,
	title = {Learning {TensorFlow} ::},
	url = {http://learningtensorflow.com/index.html},
	urldate = {2017-05-08},
	file = {Learning TensorFlow \:\::/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/IK2WHMAB/index.html:text/html}
}

@misc{noauthor_convnetjs:_nodate,
	title = {{ConvNetJS}: {Deep} {Learning} in your browser},
	url = {http://cs.stanford.edu/people/karpathy/convnetjs/},
	urldate = {2017-05-08},
	file = {ConvNetJS\: Deep Learning in your browser:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/F4UI3VBE/convnetjs.html:text/html}
}

@misc{noauthor_af_nodate,
	title = {{AF} {Classification} from a short single lead {ECG} recording: the {PhysioNet}/{Computing} in {Cardiology} {Challenge} 2017},
	url = {https://physionet.org/challenge/2017/},
	urldate = {2017-05-08},
	file = {AF Classification from a short single lead ECG recording\: the PhysioNet/Computing in Cardiology Challenge 2017:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/3NDP5D64/2017.html:text/html}
}

@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2017-05-09},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1409.1556 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/Z22ZQPHJ/Simonyan and Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/EGT38KXM/1409.html:text/html}
}

@misc{noauthor_cs231n_nodate-1,
	title = {{CS}231n {Convolutional} {Neural} {Networks} for {Visual} {Recognition}},
	url = {http://cs231n.github.io/transfer-learning/},
	urldate = {2017-05-09},
	file = {CS231n Convolutional Neural Networks for Visual Recognition:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/CIHHHV9R/transfer-learning.html:text/html}
}

@article{veit_residual_2016,
	title = {Residual {Networks} {Behave} {Like} {Ensembles} of {Relatively} {Shallow} {Networks}},
	url = {http://arxiv.org/abs/1605.06431},
	abstract = {In this work we propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training. To support this observation, we rewrite residual networks as an explicit collection of paths. Unlike traditional models, paths through residual networks vary in length. Further, a lesion study reveals that these paths show ensemble-like behavior in the sense that they do not strongly depend on each other. Finally, and most surprising, most paths are shorter than one might expect, and only the short paths are needed during training, as longer paths do not contribute any gradient. For example, most of the gradient in a residual network with 110 layers comes from paths that are only 10-34 layers deep. Our results reveal one of the key characteristics that seem to enable the training of very deep networks: Residual networks avoid the vanishing gradient problem by introducing short paths which can carry gradient throughout the extent of very deep networks.},
	urldate = {2017-05-09},
	journal = {arXiv:1605.06431 [cs]},
	author = {Veit, Andreas and Wilber, Michael and Belongie, Serge},
	month = may,
	year = {2016},
	note = {arXiv: 1605.06431},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: NIPS 2016},
	file = {arXiv\:1605.06431 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/2KJAZHKW/Veit et al. - 2016 - Residual Networks Behave Like Ensembles of Relativ.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/T55VGI5Z/1605.html:text/html}
}

@article{veit_residual_2016-1,
	title = {Residual {Networks} {Behave} {Like} {Ensembles} of {Relatively} {Shallow} {Networks}},
	url = {http://arxiv.org/abs/1605.06431},
	abstract = {In this work we propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training. To support this observation, we rewrite residual networks as an explicit collection of paths. Unlike traditional models, paths through residual networks vary in length. Further, a lesion study reveals that these paths show ensemble-like behavior in the sense that they do not strongly depend on each other. Finally, and most surprising, most paths are shorter than one might expect, and only the short paths are needed during training, as longer paths do not contribute any gradient. For example, most of the gradient in a residual network with 110 layers comes from paths that are only 10-34 layers deep. Our results reveal one of the key characteristics that seem to enable the training of very deep networks: Residual networks avoid the vanishing gradient problem by introducing short paths which can carry gradient throughout the extent of very deep networks.},
	urldate = {2017-05-09},
	journal = {arXiv:1605.06431 [cs]},
	author = {Veit, Andreas and Wilber, Michael and Belongie, Serge},
	month = may,
	year = {2016},
	note = {arXiv: 1605.06431},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: NIPS 2016},
	file = {arXiv\:1605.06431 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/429GFVZP/Veit et al. - 2016 - Residual Networks Behave Like Ensembles of Relativ.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/4HWR2GDV/1605.html:text/html}
}

@misc{noauthor_batch_nodate,
	title = {Batch {Norm} layer Â· {Artificial} {Inteligence}},
	url = {https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/batch_norm_layer.html},
	urldate = {2017-05-09},
	file = {Batch Norm layer Â· Artificial Inteligence:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/MIQ8M366/batch_norm_layer.html:text/html}
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2017-05-09},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.03167},
	keywords = {Computer Science - Learning},
	file = {arXiv\:1502.03167 PDF:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/DU525B29/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:/home/csbotos/.mozilla/firefox/l9sv74v9.default/zotero/storage/D56836GW/1502.html:text/html}
}