Research in deep learning area is getting more attention, new fields where machine learning can be introduced are looking for efficient ways to test whether previously succesful architectures can be applied or not.
To achieve a representative baseline and to allow fine tuning, it requires to maintain a stable work environment, yet flexible enough to try out new ideas.
In this work we aimed to build such a general model, that is capable to integrate handcrafted features at different level of proces and automatically summarizes our experiments for later reconsideration while making the best use of our large computational capacity with parallel runs operating on both CPU and GPU.
